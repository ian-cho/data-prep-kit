{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "40647db0-0509-4550-8b7b-bee114ca270e",
   "metadata": {},
   "source": [
    "# GneissWeb Recipe\n",
    "\n",
    "#### This notebook presents the GneissWeb recipe and applies the components in sequence to reproduce the GneissWeb processing pipeline using DPK transforms. \n",
    "<br>\n",
    "__________________________________________________________________________________________________________________________________________________________\n",
    "\n",
    "##### Contributors: Hajar Emami Gohari (Hajar.Emami@ibm.com)\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a46fe08-3f61-4ed4-95fc-afeafefd20e1",
   "metadata": {},
   "source": [
    "\n",
    "#### The GneissWeb Recipe consists of the following ingredients:\n",
    "#### - Read the input Data (Sec. 0)\n",
    "#### - Exact substring deduplication at line level (Sec. 1)\n",
    "#### - Ensemble quality annotator (Sec. 2) consisting of: \n",
    "#### &emsp;&emsp; - Custom built FastText Quality Classifier (Sec. 2.1)\n",
    "#### &emsp;&emsp; - Custom built FastText Category Classifiers (Sec. 2.2)\n",
    "#### &emsp;&emsp; - Custom built Readability Score Quality Annotator (Sec. 2.3)\n",
    "#### &emsp;&emsp; - Custom built Extreme-Tokenized-Documents Quality Annotator (Sec. 2.4)\n",
    "#### &emsp;&emsp;&emsp;&emsp; - Tokenization\n",
    "#### &emsp;&emsp;&emsp;&emsp; - Annotation\n",
    "#### - Category-aware Quality Filter (Sec. 3)\n",
    "\n",
    "#### &emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;&emsp; ![](GneissWeb_recipe_new.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "3cd3d5a9-2c03-4945-ba17-30d8170bd07f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install --no-cache \"data-prep-toolkit-transforms[rep_removal, readabilty, extreme_tokenized, filter, tokenization]==1.0.1.dev1\"\n",
    "# !pip install langcodes huggingface-hub fasttext-wheel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf2ee4b2-d3ca-4d4f-9a37-e0c029a241c2",
   "metadata": {},
   "source": [
    "### 0. Read the input parquet file\n",
    "##### Download a parquet file from HF using the HF download API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3a74dff-faee-44ae-9f0a-d7dfd8be2ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from huggingface_hub import hf_hub_download\n",
    "# import pandas as pd\n",
    "\n",
    "# REPO_ID = \"HuggingFaceFW/fineweb\"\n",
    "# FILENAME = \"data/CC-MAIN-2013-20/000_00000.parquet\"\n",
    "\n",
    "# hf_hub_download(repo_id=REPO_ID, filename=FILENAME, repo_type=\"dataset\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78871738-46dc-4ce1-ae3c-8b7c281e8258",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('input/test1.parquet', <http.client.HTTPMessage at 0x103e2efe0>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import urllib.request\n",
    "import shutil\n",
    "\n",
    "shutil.os.makedirs(\"input\", exist_ok=True)\n",
    "urllib.request.urlretrieve(\"https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/universal/rep_removal/test-data/input/test1.parquet\", \"input/test1.parquet\")\n",
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/IBM/data-prep-kit/dev/transforms/language/extreme_tokenized/test-data/input/arrow/test1.arrow\", \"tmp/input/test1.arrow\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ed3dab-30af-41c6-a5c3-f665a7c49243",
   "metadata": {},
   "source": [
    "#### Pip installations\n",
    "\n",
    "##### These pip installs need to be adapted to use the appropriate release level. Alternatively, The venv running the jupyter lab could be pre-configured with a requirement file that includes the right release.\n",
    "\n",
    "##### Example for transform developers working from git clone:\n",
    "\n",
    "##### make venv\n",
    "\n",
    "##### source venv/bin/activate\n",
    "\n",
    "##### pip install jupyterlab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "594ab090-f34d-4707-8a16-f91bfd7e36c9",
   "metadata": {},
   "source": [
    "\n",
    "### 1. Repetition Removal\n",
    "##### This component applies exact substring deduplication to remove any substring of predetermined length that repeats more than once within a single parquet file level by adapting the implementation from [deduplicate-text-datasets](https://github.com/google-research/deduplicate-text-datasets)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00652330-69bd-4652-81d1-5ffcca913742",
   "metadata": {},
   "source": [
    "<!--  -->\n",
    "#### Prerequisites\n",
    "\n",
    "##### To run the repetition removal transform, Rust is required to be installed on the machine. You can install rust following instructions [here](https://www.rust-lang.org/tools/install).\n",
    "\n",
    "##### Add Rust to $PATH\n",
    "\n",
    "##### If Rust is not added to your $PATH, run the below steps to add the rust installation location for proper execution.\n",
    "\n",
    "##### You can use the !whereis cargo command to find where rust is installed in your machine, and set the path there up to the /bin\n",
    "\n",
    "##### ex: whereis cargo produces: cargo: /Users/USERNAME/.cargo/bin/cargo\n",
    "\n",
    "##### set the $PATH to include /Users/USERNAME/.cargo/bin/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "85cbc7d3-747a-4396-8530-efcefd4751a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# pq = \"input/test1.parquet\"\n",
    "# df = pd.read_parquet(pq)\n",
    "# df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ab0fd19-dba5-4934-b510-c8c964b6ca00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hajaremami/Desktop/DPK_notebook/data-prep-kit/examples/notebooks/GneissWeb/venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "23:09:25 INFO - pipeline id pipeline_id\n",
      "INFO:data_processing.runtime.execution_configuration:pipeline id pipeline_id\n",
      "23:09:25 INFO - code location None\n",
      "INFO:data_processing.runtime.execution_configuration:code location None\n",
      "23:09:25 INFO - data factory data_ is using local data access: input_folder - input output_folder - tmp/repRemoval\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ is using local data access: input_folder - input output_folder - tmp/repRemoval\n",
      "23:09:25 INFO - data factory data_ max_files -1, n_sample -1\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ max_files -1, n_sample -1\n",
      "23:09:25 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "23:09:25 INFO - orchestrator rep_removal started at 2025-02-07 23:09:25\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:orchestrator rep_removal started at 2025-02-07 23:09:25\n",
      "23:09:25 INFO - Number of files is 1, source profile {'max_file_size': 0.04273414611816406, 'min_file_size': 0.04273414611816406, 'total_file_size': 0.04273414611816406}\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Number of files is 1, source profile {'max_file_size': 0.04273414611816406, 'min_file_size': 0.04273414611816406, 'total_file_size': 0.04273414611816406}\n",
      "INFO:root:timeout is: 60.616790582403965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu speed: 3228 MHz, Cores: 10\n",
      "gpu_usage: 0.00%, GPU speed: 0 MHz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:root:running the merge\n",
      "INFO:root:merging complete\n",
      "\u001b[1m\u001b[32m    Finished\u001b[0m dev [optimized + debuginfo] target(s) in 0.07s\n",
      "\u001b[1m\u001b[32m     Running\u001b[0m `venv/lib/python3.10/site-packages/dpk_rep_removal/rust/target/debug/dedup_dataset self-similar --data-file /var/folders/f3/5zmfvg4j539bhmnsxzqmbc2h0000gn/T/tmpwxurx_g9/save_dir/parquet --length-threshold 50 --cache-dir /var/folders/f3/5zmfvg4j539bhmnsxzqmbc2h0000gn/T/tmpwxurx_g9/cache --num-threads 1 --frequency-threshold 1 --retain-first-copy`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start load!\n",
      "0 / 19909 \n",
      "Duplicates found: 7250\n",
      "Total time taken: 7ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:09:27 INFO - Completed 1 files (100.0%) in 0.036 min\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Completed 1 files (100.0%) in 0.036 min\n",
      "23:09:27 INFO - Done processing 1 files, waiting for flush() completion.\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Done processing 1 files, waiting for flush() completion.\n",
      "23:09:27 INFO - done flushing in 0.0 sec\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:done flushing in 0.0 sec\n",
      "23:09:27 INFO - Completed execution in 0.036 min, execution result 0\n",
      "INFO:data_processing.runtime.pure_python.transform_launcher:Completed execution in 0.036 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.33 s, sys: 2.11 s, total: 3.44 s\n",
      "Wall time: 7.5 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "from dpk_rep_removal.runtime import RepRemoval\n",
    "\n",
    "RepRemoval(input_folder= \"input\",\n",
    "            output_folder= \"tmp/repRemoval\",\n",
    "            rep_removal_contents_column_name='text', \n",
    "            rep_removal_num_threads='1',\n",
    "            ).transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0f8c01ce-87d0-4043-a72e-0ff100b39a04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# pq = \"tmp/repRemoval/test1.parquet\"\n",
    "# df = pd.read_parquet(pq)\n",
    "# df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5ff67d-7ce9-4e7c-b283-bb75739ea876",
   "metadata": {},
   "source": [
    "### 2. Annotation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d1a2b7-bc06-4dba-ae7c-764444f79da4",
   "metadata": {},
   "source": [
    "### 2.1. Fasttext Quality Annotator\n",
    "##### This step annotates the documents using two FastText quality classifiers: (i) the fastText classifier from [DCLM](https://arxiv.org/pdf/2406.11794) and (ii) our own fastText classifier trained on a mix of high-quality synthetic data and data annotated by an LLM for high educational value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08f27e62-a2fc-4c7a-bc6f-f6f54985c977",
   "metadata": {},
   "outputs": [],
   "source": [
    "credential= \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df8ef14a-6970-4eb1-a6ac-b2f92259d894",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:05:42 INFO - parameters are : {'gcls_model_credential': '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', 'gcls_model_file_name': 'fasttext_gneissweb_quality_annotator.bin', 'gcls_model_url': 'ibm-research/GneissWeb.Quality_annotator', 'gcls_content_column_name': 'text', 'gcls_output_label_column_name': 'cosmo_fasttext_label', 'gcls_output_score_column_name': 'cosmo_fasttext_score'}\n",
      "INFO:dpk_gneissweb_classification.transform:parameters are : {'gcls_model_credential': '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', 'gcls_model_file_name': 'fasttext_gneissweb_quality_annotator.bin', 'gcls_model_url': 'ibm-research/GneissWeb.Quality_annotator', 'gcls_content_column_name': 'text', 'gcls_output_label_column_name': 'cosmo_fasttext_label', 'gcls_output_score_column_name': 'cosmo_fasttext_score'}\n",
      "12:05:42 INFO - pipeline id pipeline_id\n",
      "INFO:data_processing.runtime.execution_configuration:pipeline id pipeline_id\n",
      "12:05:42 INFO - code location None\n",
      "INFO:data_processing.runtime.execution_configuration:code location None\n",
      "12:05:42 INFO - data factory data_ is using local data access: input_folder - tmp/repRemoval output_folder - tmp/fasttext/quality\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ is using local data access: input_folder - tmp/repRemoval output_folder - tmp/fasttext/quality\n",
      "12:05:42 INFO - data factory data_ max_files -1, n_sample -1\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ max_files -1, n_sample -1\n",
      "12:05:42 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "12:05:42 INFO - orchestrator gcls started at 2025-02-10 12:05:42\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:orchestrator gcls started at 2025-02-10 12:05:42\n",
      "12:05:42 INFO - Number of files is 1, source profile {'max_file_size': 0.03802490234375, 'min_file_size': 0.03802490234375, 'total_file_size': 0.03802490234375}\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Number of files is 1, source profile {'max_file_size': 0.03802490234375, 'min_file_size': 0.03802490234375, 'total_file_size': 0.03802490234375}\n",
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: huggingface.co\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /ibm-research/GneissWeb.Quality_annotator/resolve/main/fasttext_gneissweb_quality_annotator.bin HTTP/1.1\" 302 0\n",
      "12:05:45 INFO - Completed 1 files (100.0%) in 0.0 min\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Completed 1 files (100.0%) in 0.0 min\n",
      "12:05:45 INFO - Done processing 1 files, waiting for flush() completion.\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Done processing 1 files, waiting for flush() completion.\n",
      "12:05:45 INFO - done flushing in 0.0 sec\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:done flushing in 0.0 sec\n",
      "12:05:45 INFO - Completed execution in 0.054 min, execution result 0\n",
      "INFO:data_processing.runtime.pure_python.transform_launcher:Completed execution in 0.054 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.25 s, sys: 1.04 s, total: 2.29 s\n",
      "Wall time: 3.24 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "from dpk_gneissweb_classification.transform_python import Classification\n",
    "\n",
    "Classification(input_folder= \"tmp/repRemoval\",\n",
    "        output_folder= \"tmp/fasttext/quality\",\n",
    "        gcls_model_credential= credential,\n",
    "        gcls_model_file_name= \"fasttext_gneissweb_quality_annotator.bin\",\n",
    "        gcls_model_url= \"ibm-research/GneissWeb.Quality_annotator\",\n",
    "        gcls_output_label_column_name= \"cosmo_fastText_label\",\n",
    "        gcls_output_score_column_name= \"cosmo_fastText_score\",\n",
    "        gcls_content_column_name= \"text\").transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b12962e6-44b4-45b8-9c63-0a33a4e5c0dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:05:48 INFO - parameters are : {'gcls_model_credential': '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', 'gcls_model_file_name': 'openhermes_reddit_eli5_vs_rw_v2_bigram_200k_train.bin', 'gcls_model_url': 'mlfoundations/fasttext-oh-eli5', 'gcls_content_column_name': 'text', 'gcls_output_label_column_name': 'dclm_Fasttext_label', 'gcls_output_score_column_name': 'dclm_Fasttext_score'}\n",
      "INFO:dpk_gneissweb_classification.transform:parameters are : {'gcls_model_credential': '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', 'gcls_model_file_name': 'openhermes_reddit_eli5_vs_rw_v2_bigram_200k_train.bin', 'gcls_model_url': 'mlfoundations/fasttext-oh-eli5', 'gcls_content_column_name': 'text', 'gcls_output_label_column_name': 'dclm_Fasttext_label', 'gcls_output_score_column_name': 'dclm_Fasttext_score'}\n",
      "12:05:48 INFO - pipeline id pipeline_id\n",
      "INFO:data_processing.runtime.execution_configuration:pipeline id pipeline_id\n",
      "12:05:48 INFO - code location None\n",
      "INFO:data_processing.runtime.execution_configuration:code location None\n",
      "12:05:48 INFO - data factory data_ is using local data access: input_folder - tmp/fasttext/quality output_folder - tmp/fasttext/DCLM\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ is using local data access: input_folder - tmp/fasttext/quality output_folder - tmp/fasttext/DCLM\n",
      "12:05:48 INFO - data factory data_ max_files -1, n_sample -1\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ max_files -1, n_sample -1\n",
      "12:05:48 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "12:05:48 INFO - orchestrator gcls started at 2025-02-10 12:05:48\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:orchestrator gcls started at 2025-02-10 12:05:48\n",
      "12:05:48 INFO - Number of files is 1, source profile {'max_file_size': 0.03887176513671875, 'min_file_size': 0.03887176513671875, 'total_file_size': 0.03887176513671875}\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Number of files is 1, source profile {'max_file_size': 0.03887176513671875, 'min_file_size': 0.03887176513671875, 'total_file_size': 0.03887176513671875}\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /mlfoundations/fasttext-oh-eli5/resolve/main/openhermes_reddit_eli5_vs_rw_v2_bigram_200k_train.bin HTTP/1.1\" 302 0\n",
      "12:05:50 INFO - Completed 1 files (100.0%) in 0.0 min\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Completed 1 files (100.0%) in 0.0 min\n",
      "12:05:50 INFO - Done processing 1 files, waiting for flush() completion.\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Done processing 1 files, waiting for flush() completion.\n",
      "12:05:50 INFO - done flushing in 0.0 sec\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:done flushing in 0.0 sec\n",
      "12:05:50 INFO - Completed execution in 0.037 min, execution result 0\n",
      "INFO:data_processing.runtime.pure_python.transform_launcher:Completed execution in 0.037 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.16 s, sys: 815 ms, total: 1.97 s\n",
      "Wall time: 2.24 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "Classification(input_folder= \"tmp/fasttext/quality\",\n",
    "        output_folder= \"tmp/fasttext/DCLM\",\n",
    "        gcls_model_credential= credential,\n",
    "        gcls_model_file_name= \"openhermes_reddit_eli5_vs_rw_v2_bigram_200k_train.bin\",\n",
    "        gcls_model_url= \"mlfoundations/fasttext-oh-eli5\",\n",
    "        gcls_output_label_column_name= \"dclm_fastText_label\",\n",
    "        gcls_output_score_column_name= \"dclm_fastText_score\",\n",
    "        gcls_content_column_name= \"text\").transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b3ad219-944d-4592-81b1-84a1d26ae99c",
   "metadata": {},
   "source": [
    "### 2.2. Document Category Classifiers\n",
    "##### This step annotates the documents using four FastText category classifiers:\n",
    "##### &emsp;&emsp;  1. Science\n",
    "##### &emsp;&emsp;  2. Education\n",
    "##### &emsp;&emsp;  3. Technology & computing\n",
    "##### &emsp;&emsp;  4. Medical health"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4737ffd4-48f2-4106-80a9-72ef1efb21e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:05 INFO - parameters are : {'gcls_model_credential': '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', 'gcls_model_file_name': 'fasttext_medical.bin', 'gcls_model_url': 'ibm-research/GneissWeb.Med_classifier', 'gcls_content_column_name': 'text', 'gcls_output_label_column_name': 'medical_label', 'gcls_output_score_column_name': 'medical_score'}\n",
      "INFO:dpk_gneissweb_classification.transform:parameters are : {'gcls_model_credential': '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', 'gcls_model_file_name': 'fasttext_medical.bin', 'gcls_model_url': 'ibm-research/GneissWeb.Med_classifier', 'gcls_content_column_name': 'text', 'gcls_output_label_column_name': 'medical_label', 'gcls_output_score_column_name': 'medical_score'}\n",
      "12:06:05 INFO - pipeline id pipeline_id\n",
      "INFO:data_processing.runtime.execution_configuration:pipeline id pipeline_id\n",
      "12:06:05 INFO - code location None\n",
      "INFO:data_processing.runtime.execution_configuration:code location None\n",
      "12:06:05 INFO - data factory data_ is using local data access: input_folder - tmp/fasttext/DCLM output_folder - tmp/fasttext/medical\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ is using local data access: input_folder - tmp/fasttext/DCLM output_folder - tmp/fasttext/medical\n",
      "12:06:05 INFO - data factory data_ max_files -1, n_sample -1\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ max_files -1, n_sample -1\n",
      "12:06:05 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "12:06:05 INFO - orchestrator gcls started at 2025-02-10 12:06:05\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:orchestrator gcls started at 2025-02-10 12:06:05\n",
      "12:06:05 INFO - Number of files is 1, source profile {'max_file_size': 0.03971099853515625, 'min_file_size': 0.03971099853515625, 'total_file_size': 0.03971099853515625}\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Number of files is 1, source profile {'max_file_size': 0.03971099853515625, 'min_file_size': 0.03971099853515625, 'total_file_size': 0.03971099853515625}\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /ibm-research/GneissWeb.Med_classifier/resolve/main/fasttext_medical.bin HTTP/1.1\" 302 0\n",
      "12:06:08 INFO - Completed 1 files (100.0%) in 0.0 min\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Completed 1 files (100.0%) in 0.0 min\n",
      "12:06:08 INFO - Done processing 1 files, waiting for flush() completion.\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Done processing 1 files, waiting for flush() completion.\n",
      "12:06:08 INFO - done flushing in 0.0 sec\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:done flushing in 0.0 sec\n",
      "12:06:08 INFO - Completed execution in 0.053 min, execution result 0\n",
      "INFO:data_processing.runtime.pure_python.transform_launcher:Completed execution in 0.053 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.91 s, sys: 1.12 s, total: 3.03 s\n",
      "Wall time: 3.2 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "Classification(input_folder= \"tmp/fasttext/DCLM\",\n",
    "        output_folder= \"tmp/fasttext/medical\",\n",
    "        gcls_model_credential= credential,\n",
    "        gcls_model_file_name= \"fasttext_medical.bin\",\n",
    "        gcls_model_url= \"ibm-research/GneissWeb.Med_classifier\",\n",
    "        gcls_output_label_column_name= \"medical_label\",\n",
    "        gcls_output_score_column_name= \"medical_score\",\n",
    "        gcls_content_column_name= \"text\").transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d91107fa-772d-4939-800b-c9e0a0fa7e1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:16 INFO - parameters are : {'gcls_model_credential': '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', 'gcls_model_file_name': 'fasttext_education.bin', 'gcls_model_url': 'ibm-research/GneissWeb.Edu_classifier', 'gcls_content_column_name': 'text', 'gcls_output_label_column_name': 'education_label', 'gcls_output_score_column_name': 'education_score'}\n",
      "INFO:dpk_gneissweb_classification.transform:parameters are : {'gcls_model_credential': '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', 'gcls_model_file_name': 'fasttext_education.bin', 'gcls_model_url': 'ibm-research/GneissWeb.Edu_classifier', 'gcls_content_column_name': 'text', 'gcls_output_label_column_name': 'education_label', 'gcls_output_score_column_name': 'education_score'}\n",
      "12:06:16 INFO - pipeline id pipeline_id\n",
      "INFO:data_processing.runtime.execution_configuration:pipeline id pipeline_id\n",
      "12:06:16 INFO - code location None\n",
      "INFO:data_processing.runtime.execution_configuration:code location None\n",
      "12:06:16 INFO - data factory data_ is using local data access: input_folder - tmp/fasttext/medical output_folder - tmp/fasttext/education\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ is using local data access: input_folder - tmp/fasttext/medical output_folder - tmp/fasttext/education\n",
      "12:06:16 INFO - data factory data_ max_files -1, n_sample -1\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ max_files -1, n_sample -1\n",
      "12:06:16 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "12:06:16 INFO - orchestrator gcls started at 2025-02-10 12:06:16\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:orchestrator gcls started at 2025-02-10 12:06:16\n",
      "12:06:16 INFO - Number of files is 1, source profile {'max_file_size': 0.04049396514892578, 'min_file_size': 0.04049396514892578, 'total_file_size': 0.04049396514892578}\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Number of files is 1, source profile {'max_file_size': 0.04049396514892578, 'min_file_size': 0.04049396514892578, 'total_file_size': 0.04049396514892578}\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /ibm-research/GneissWeb.Edu_classifier/resolve/main/fasttext_education.bin HTTP/1.1\" 302 0\n",
      "12:06:19 INFO - Completed 1 files (100.0%) in 0.0 min\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Completed 1 files (100.0%) in 0.0 min\n",
      "12:06:19 INFO - Done processing 1 files, waiting for flush() completion.\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Done processing 1 files, waiting for flush() completion.\n",
      "12:06:19 INFO - done flushing in 0.0 sec\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:done flushing in 0.0 sec\n",
      "12:06:19 INFO - Completed execution in 0.047 min, execution result 0\n",
      "INFO:data_processing.runtime.pure_python.transform_launcher:Completed execution in 0.047 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.69 s, sys: 996 ms, total: 2.68 s\n",
      "Wall time: 2.82 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "Classification(input_folder= \"tmp/fasttext/medical\",\n",
    "        output_folder= \"tmp/fasttext/education\",\n",
    "        gcls_model_credential= credential,\n",
    "        gcls_model_file_name= \"fasttext_education.bin\",\n",
    "        gcls_model_url= \"ibm-research/GneissWeb.Edu_classifier\",\n",
    "        gcls_output_label_column_name= \"education_label\",\n",
    "        gcls_output_score_column_name= \"education_score\",\n",
    "        gcls_content_column_name= \"text\").transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "95f8d302-86b6-494f-85e9-1d9056bb2473",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:22 INFO - parameters are : {'gcls_model_credential': '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', 'gcls_model_file_name': 'fasttext_technology_computing.bin', 'gcls_model_url': 'ibm-research/GneissWeb.Tech_classifier', 'gcls_content_column_name': 'text', 'gcls_output_label_column_name': 'technology_computing_label', 'gcls_output_score_column_name': 'technology_computing_score'}\n",
      "INFO:dpk_gneissweb_classification.transform:parameters are : {'gcls_model_credential': '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', 'gcls_model_file_name': 'fasttext_technology_computing.bin', 'gcls_model_url': 'ibm-research/GneissWeb.Tech_classifier', 'gcls_content_column_name': 'text', 'gcls_output_label_column_name': 'technology_computing_label', 'gcls_output_score_column_name': 'technology_computing_score'}\n",
      "12:06:22 INFO - pipeline id pipeline_id\n",
      "INFO:data_processing.runtime.execution_configuration:pipeline id pipeline_id\n",
      "12:06:22 INFO - code location None\n",
      "INFO:data_processing.runtime.execution_configuration:code location None\n",
      "12:06:22 INFO - data factory data_ is using local data access: input_folder - tmp/fasttext/education output_folder - tmp/fasttext/technology\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ is using local data access: input_folder - tmp/fasttext/education output_folder - tmp/fasttext/technology\n",
      "12:06:22 INFO - data factory data_ max_files -1, n_sample -1\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ max_files -1, n_sample -1\n",
      "12:06:22 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "12:06:22 INFO - orchestrator gcls started at 2025-02-10 12:06:22\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:orchestrator gcls started at 2025-02-10 12:06:22\n",
      "12:06:22 INFO - Number of files is 1, source profile {'max_file_size': 0.04126548767089844, 'min_file_size': 0.04126548767089844, 'total_file_size': 0.04126548767089844}\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Number of files is 1, source profile {'max_file_size': 0.04126548767089844, 'min_file_size': 0.04126548767089844, 'total_file_size': 0.04126548767089844}\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /ibm-research/GneissWeb.Tech_classifier/resolve/main/fasttext_technology_computing.bin HTTP/1.1\" 302 0\n",
      "12:06:25 INFO - Completed 1 files (100.0%) in 0.0 min\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Completed 1 files (100.0%) in 0.0 min\n",
      "12:06:25 INFO - Done processing 1 files, waiting for flush() completion.\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Done processing 1 files, waiting for flush() completion.\n",
      "12:06:25 INFO - done flushing in 0.0 sec\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:done flushing in 0.0 sec\n",
      "12:06:25 INFO - Completed execution in 0.06 min, execution result 0\n",
      "INFO:data_processing.runtime.pure_python.transform_launcher:Completed execution in 0.06 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.95 s, sys: 1.31 s, total: 3.25 s\n",
      "Wall time: 3.59 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "Classification(input_folder= \"tmp/fasttext/education\",\n",
    "        output_folder= \"tmp/fasttext/technology\",\n",
    "        gcls_model_credential= credential,\n",
    "        gcls_model_file_name= \"fasttext_technology_computing.bin\",\n",
    "        gcls_model_url= \"ibm-research/GneissWeb.Tech_classifier\",\n",
    "        gcls_output_label_column_name= \"technology_computing_label\",\n",
    "        gcls_output_score_column_name= \"technology_computing_score\",\n",
    "        gcls_content_column_name= \"text\").transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "008247a0-568e-46f0-911e-93f8587e3156",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:06:27 INFO - parameters are : {'gcls_model_credential': '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', 'gcls_model_file_name': 'fasttext_science.bin', 'gcls_model_url': 'ibm-research/GneissWeb.Sci_classifier', 'gcls_content_column_name': 'text', 'gcls_output_label_column_name': 'science_label', 'gcls_output_score_column_name': 'science_score'}\n",
      "INFO:dpk_gneissweb_classification.transform:parameters are : {'gcls_model_credential': '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', 'gcls_model_file_name': 'fasttext_science.bin', 'gcls_model_url': 'ibm-research/GneissWeb.Sci_classifier', 'gcls_content_column_name': 'text', 'gcls_output_label_column_name': 'science_label', 'gcls_output_score_column_name': 'science_score'}\n",
      "12:06:27 INFO - pipeline id pipeline_id\n",
      "INFO:data_processing.runtime.execution_configuration:pipeline id pipeline_id\n",
      "12:06:27 INFO - code location None\n",
      "INFO:data_processing.runtime.execution_configuration:code location None\n",
      "12:06:27 INFO - data factory data_ is using local data access: input_folder - tmp/fasttext/technology output_folder - tmp/fasttext/science\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ is using local data access: input_folder - tmp/fasttext/technology output_folder - tmp/fasttext/science\n",
      "12:06:27 INFO - data factory data_ max_files -1, n_sample -1\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ max_files -1, n_sample -1\n",
      "12:06:27 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "INFO:data_processing.data_access.data_access_factory_base57a8845a-6882-43cd-8e6f-24f330ca6ad4:data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "12:06:27 INFO - orchestrator gcls started at 2025-02-10 12:06:27\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:orchestrator gcls started at 2025-02-10 12:06:27\n",
      "12:06:27 INFO - Number of files is 1, source profile {'max_file_size': 0.04215717315673828, 'min_file_size': 0.04215717315673828, 'total_file_size': 0.04215717315673828}\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Number of files is 1, source profile {'max_file_size': 0.04215717315673828, 'min_file_size': 0.04215717315673828, 'total_file_size': 0.04215717315673828}\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /ibm-research/GneissWeb.Sci_classifier/resolve/main/fasttext_science.bin HTTP/1.1\" 302 0\n",
      "12:06:31 INFO - Completed 1 files (100.0%) in 0.0 min\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Completed 1 files (100.0%) in 0.0 min\n",
      "12:06:31 INFO - Done processing 1 files, waiting for flush() completion.\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:Done processing 1 files, waiting for flush() completion.\n",
      "12:06:31 INFO - done flushing in 0.0 sec\n",
      "INFO:data_processing.runtime.pure_python.transform_orchestrator:done flushing in 0.0 sec\n",
      "12:06:31 INFO - Completed execution in 0.069 min, execution result 0\n",
      "INFO:data_processing.runtime.pure_python.transform_launcher:Completed execution in 0.069 min, execution result 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.38 s, sys: 1.49 s, total: 3.87 s\n",
      "Wall time: 4.18 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "Classification(input_folder= \"tmp/fasttext/technology\",\n",
    "        output_folder= \"tmp/fasttext/science\",\n",
    "        gcls_model_credential= credential,\n",
    "        gcls_model_file_name= \"fasttext_science.bin\",\n",
    "        gcls_model_url= \"ibm-research/GneissWeb.Sci_classifier\",\n",
    "        gcls_output_label_column_name= \"science_label\",\n",
    "        gcls_output_score_column_name= \"science_score\",\n",
    "        gcls_content_column_name= \"text\").transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e29c9a90-f0ba-4849-a45c-0a582f23ac2d",
   "metadata": {},
   "source": [
    "### 2.3. Readability Scores Quality Annotator\n",
    "##### This transform calculates the McAlpine-EFLAW readability score for each document in the output parquet file from the previous step and adds McAlpine-EFLAW readability score column to the data.\n",
    "\n",
    "##### McAlpine-EFLAW readability score of a document is a numerical score computed as a function of the number of words in a document plus the number of mini-words (consisting of â‰¤ 3 characters) divided by the number of sentences. Lower score means the document is easier to understand for a reader with English as a foreign language. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "96a2e3cf-7c3d-4c5b-bb28-bde0bddb7390",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:41:15 INFO - Readability parameters are : {'readability_contents_column_name': 'text', 'readability_score_list': 'mcalpine_eflaw_textstat'}\n",
      "11:41:15 INFO - pipeline id pipeline_id\n",
      "11:41:15 INFO - code location None\n",
      "11:41:15 INFO - data factory data_ is using local data access: input_folder - tmp/fasttext/science output_folder - tmp/readabilty\n",
      "11:41:15 INFO - data factory data_ max_files -1, n_sample -1\n",
      "11:41:15 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "11:41:15 INFO - orchestrator readability started at 2025-02-14 11:41:15\n",
      "11:41:15 INFO - Number of files is 1, source profile {'max_file_size': 0.042934417724609375, 'min_file_size': 0.042934417724609375, 'total_file_size': 0.042934417724609375}\n",
      "11:41:15 INFO - Completed 1 files (100.0%) in 0.0 min\n",
      "11:41:15 INFO - Done processing 1 files, waiting for flush() completion.\n",
      "11:41:15 INFO - done flushing in 0.0 sec\n",
      "11:41:15 INFO - Completed execution in 0.0 min, execution result 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install textstat\n",
    "from dpk_readability.runtime import Readability\n",
    "\n",
    "Readability(\n",
    "    input_folder=\"tmp/fasttext/science\",\n",
    "    output_folder=\"tmp/readabilty\",\n",
    "    readability_contents_column_name=\"text\",\n",
    ").transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fc90cacf-0042-4e63-b7d9-ff4e105fc25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "\n",
    "# pq = \"tmp/readabilty/test1.parquet\"\n",
    "# df = pd.read_parquet(pq)\n",
    "# df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e09597a-d8d9-4e88-b1ef-4502f54447de",
   "metadata": {},
   "source": [
    "### 2.4. Extreme-Tokenized-Documents Quality Annotator\n",
    "##### This annotator retrieves the tokens generated for a set of documents. Then, it calculates, for each document, the size and the total number of characters. The number of tokens is divided by the size and by the number of characters, and the resulting values are stored in two columns ( tokens_per_doc_size and tokens_per_doc_num_chars).\n",
    "\n",
    "##### The annotator transform annotates the input table with 5 columns:\n",
    "\n",
    "##### &emsp;&emsp;1. doc_num_tokens - number of tokens for each document\n",
    "##### &emsp;&emsp;2. doc_size_kbs - document size in kb\n",
    "##### &emsp;&emsp;3. doc_num_chars - number of characters in the document\n",
    "##### &emsp;&emsp;4. tokens_per_doc_size - ratio between number of tokens and document size\n",
    "##### &emsp;&emsp;5. tokens_per_doc_num_chars - ratio between number of tokens and number of characters in document\n",
    "##### Documents with extremely high or low number of tokens per character (or tokens per byte) are identified as extreme-tokenized documents and can be excluded in the filtering step.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e805d12-418d-4e00-beed-8b570b9f2801",
   "metadata": {},
   "source": [
    "#### 2.4.1 Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92501596-1c2c-4a8f-80f2-155afd10ee89",
   "metadata": {},
   "outputs": [],
   "source": [
    "## packages needed for the tokenization\n",
    "# !pip install \"transformers>=4.38.2\" \"torch\" \"python-dotenv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "734018bf-8330-4fe3-870f-b14c87da8b91",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11:52:31 INFO - pipeline id pipeline_id\n",
      "11:52:31 INFO - code location None\n",
      "11:52:31 INFO - data factory data_ is using local data access: input_folder - tmp/readabilty output_folder - tmp/arrows\n",
      "11:52:31 INFO - data factory data_ max_files -1, n_sample -1\n",
      "11:52:31 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "11:52:31 INFO - orchestrator Tokenization2Arrow started at 2025-02-14 11:52:31\n",
      "11:52:31 INFO - Number of files is 1, source profile {'max_file_size': 0.03496551513671875, 'min_file_size': 0.03496551513671875, 'total_file_size': 0.03496551513671875}\n",
      "11:52:31 INFO - Tokenizer config['tokenizer'] = 'bigcode/starcoder' loaded.\n",
      "11:52:31 INFO - Tokenization2ArrowTransform.transform_binary file_name = '/Users/hajaremami/Desktop/DPK_notebook/data-prep-kit/examples/notebooks/GneissWeb/tmp/readabilty/test1.parquet'\n",
      "11:52:31 INFO - Completed 1 files (100.0%) in 0.0 min\n",
      "11:52:31 INFO - Done processing 1 files, waiting for flush() completion.\n",
      "11:52:31 INFO - done flushing in 0.0 sec\n",
      "11:52:31 INFO - Completed execution in 0.007 min, execution result 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dpk_tokenization2arrow.transform_python import Tokenization2Arrow\n",
    "\n",
    "Tokenization2Arrow(\n",
    "        input_folder= \"tmp/readabilty\",\n",
    "        output_folder= \"tmp/arrows\",\n",
    "        tkn_tokenizer=  \"bigcode/starcoder\",\n",
    "        tkn_doc_id_column= \"id\",\n",
    "        tkn_doc_content_column= \"text\",\n",
    "        tkn_chunk_size= 20_000).transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "797926be-09b3-4d39-9c8f-aba4f7bef4e9",
   "metadata": {},
   "source": [
    "#### 2.4.2 Annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "02e23cb3-a184-409d-b6cf-5649f5e35d21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "12:07:51 INFO - data factory et_ is using local configuration without input/output path\n",
      "12:07:51 INFO - data factory et_ max_files -1, n_sample -1\n",
      "12:07:51 INFO - data factory et_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "12:07:51 INFO - pipeline id pipeline_id\n",
      "12:07:51 INFO - code location None\n",
      "12:07:51 INFO - data factory data_ is using local data access: input_folder - tmp/readabilty output_folder - tmp/extreme_tokenized\n",
      "12:07:51 INFO - data factory data_ max_files -1, n_sample -1\n",
      "12:07:51 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "12:07:51 INFO - orchestrator et started at 2025-02-14 12:07:51\n",
      "12:07:51 INFO - Number of files is 1, source profile {'max_file_size': 0.03496551513671875, 'min_file_size': 0.03496551513671875, 'total_file_size': 0.03496551513671875}\n",
      "12:07:51 INFO - Transforming table with 15 rows from file /Users/hajaremami/Desktop/DPK_notebook/data-prep-kit/examples/notebooks/GneissWeb/tmp/readabilty/test1.parquet\n",
      "12:07:51 WARNING - Exception processing file /Users/hajaremami/Desktop/DPK_notebook/data-prep-kit/examples/notebooks/GneissWeb/tmp/readabilty/test1.parquet: Traceback (most recent call last):\n",
      "  File \"/Users/hajaremami/Desktop/DPK_notebook/data-prep-kit/examples/notebooks/GneissWeb/venv/lib/python3.10/site-packages/data_processing/runtime/transform_file_processor.py\", line 79, in process_file\n",
      "    out_files, stats = self.transform.transform_binary(file_name=f_name, byte_array=filedata)\n",
      "  File \"/Users/hajaremami/Desktop/DPK_notebook/data-prep-kit/examples/notebooks/GneissWeb/venv/lib/python3.10/site-packages/data_processing/transform/table_transform.py\", line 59, in transform_binary\n",
      "    out_tables, stats = self.transform(table=table, file_name=file_name)\n",
      "  File \"/Users/hajaremami/Desktop/DPK_notebook/data-prep-kit/examples/notebooks/GneissWeb/venv/lib/python3.10/site-packages/dpk_extreme_tokenized/transform.py\", line 99, in transform\n",
      "    tokens_per_doc_size[index] = doc_num_tokens[index] / (doc_size_kbs[index] * 1024)\n",
      "IndexError: list index out of range\n",
      "\n",
      "12:07:51 INFO - Completed 1 files (100.0%) in 0.0 min\n",
      "12:07:51 INFO - Done processing 1 files, waiting for flush() completion.\n",
      "12:07:51 INFO - done flushing in 0.0 sec\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hajaremami/Desktop/DPK_notebook/data-prep-kit/examples/notebooks/GneissWeb/venv/lib/python3.10/site-packages/data_processing/runtime/pure_python/transform_orchestrator.py\", line 131, in orchestrate\n",
      "    stats[\"processing_time\"] = round(stats[\"processing_time\"], 3)\n",
      "KeyError: 'processing_time'\n",
      "12:07:51 ERROR - Exception during execution 'processing_time': None\n",
      "12:07:51 INFO - Completed execution in 0.0 min, execution result 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dpk_extreme_tokenized.runtime import ExtremeTokenized\n",
    "\n",
    "ExtremeTokenized(\n",
    "    input_folder=\"tmp/readabilty\",\n",
    "    output_folder=\"tmp/extreme_tokenized\",\n",
    "    et_contents_column_name=\"text\",\n",
    "    et_arrow_path=\"tmp/arrows\",\n",
    ").transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eadce7d7-1e39-4c1b-8f0b-39b115d8223a",
   "metadata": {},
   "source": [
    "### 3. Category-aware Ensemble Quality Filter\n",
    "##### This filtering step filters out low-quality documents from the input data using multiple quality annotators and by leveraging the category information of documents. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9c2030da-40a7-4eca-8841-3b5e59165694",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23:14:32 INFO - pipeline id pipeline_id\n",
      "23:14:32 INFO - code location None\n",
      "23:14:32 INFO - data factory data_ is using local data access: input_folder - tmp/readabilty output_folder - output\n",
      "23:14:32 INFO - data factory data_ max_files -1, n_sample -1\n",
      "23:14:32 INFO - data factory data_ Not using data sets, checkpointing False, max files -1, random samples -1, files to use ['.parquet'], files to checkpoint ['.parquet']\n",
      "23:14:32 INFO - orchestrator filter started at 2025-02-13 23:14:32\n",
      "23:14:32 INFO - Number of files is 1, source profile {'max_file_size': 0.05427265167236328, 'min_file_size': 0.05427265167236328, 'total_file_size': 0.05427265167236328}\n",
      "23:14:32 WARNING - Exception processing file /Users/hajaremami/Desktop/DPK_notebook/data-prep-kit/examples/notebooks/GneissWeb/tmp/readabilty/test1.parquet: Traceback (most recent call last):\n",
      "  File \"/Users/hajaremami/Desktop/DPK_notebook/data-prep-kit/examples/notebooks/GneissWeb/venv/lib/python3.10/site-packages/data_processing/runtime/transform_file_processor.py\", line 79, in process_file\n",
      "    out_files, stats = self.transform.transform_binary(file_name=f_name, byte_array=filedata)\n",
      "  File \"/Users/hajaremami/Desktop/DPK_notebook/data-prep-kit/examples/notebooks/GneissWeb/venv/lib/python3.10/site-packages/data_processing/transform/table_transform.py\", line 59, in transform_binary\n",
      "    out_tables, stats = self.transform(table=table, file_name=file_name)\n",
      "  File \"/Users/hajaremami/Desktop/DPK_notebook/data-prep-kit/examples/notebooks/GneissWeb/venv/lib/python3.10/site-packages/dpk_filter/transform.py\", line 97, in transform\n",
      "    filter_table = duckdb.execute(criterion_sql).arrow()\n",
      "duckdb.duckdb.BinderException: Binder Error: Referenced column \"tokens_per_doc_num_chars\" not found in FROM clause!\n",
      "Candidate bindings: \"token_count\", \"watsonnlp_top_score\", \"cosmo_10k_edu_fasttext_score\", \"education_score\", \"technology_computing_score\"\n",
      "\n",
      "LINE 1: ...\" > 0.002 OR \"cosmo_10k_edu_fasttext_score\" > 0.03)) AND (((tokens_per_doc_num_chars BETWEEN 0.1 AND 0.5) AND (technolo...\n",
      "                                                                       ^\n",
      "\n",
      "23:14:32 INFO - Completed 1 files (100.0%) in 0.0 min\n",
      "23:14:32 INFO - Done processing 1 files, waiting for flush() completion.\n",
      "23:14:32 INFO - done flushing in 0.0 sec\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/hajaremami/Desktop/DPK_notebook/data-prep-kit/examples/notebooks/GneissWeb/venv/lib/python3.10/site-packages/data_processing/runtime/pure_python/transform_orchestrator.py\", line 131, in orchestrate\n",
      "    stats[\"processing_time\"] = round(stats[\"processing_time\"], 3)\n",
      "KeyError: 'processing_time'\n",
      "23:14:32 ERROR - Exception during execution 'processing_time': None\n",
      "23:14:32 INFO - Completed execution in 0.0 min, execution result 1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dpk_filter.transform_python import Filter\n",
    "\n",
    "Filter(input_folder= \"tmp/readabilty\",\n",
    "        output_folder= \"output\",\n",
    "        filter_criteria_list= \n",
    "        # ['((\"dclm_fasttext_score\" > 0.002 OR \"cosmo_10k_edu_fasttext_score\" > 0.03)) AND (((mcalpine_eflaw_textstat < 70) AND (technology_computing_label IN ('technology') OR medical_label IN ('medical') OR education_label IN ('education') OR science_label IN ('science'))) OR ((mcalpine_eflaw_textstat < 30) AND (technology_computing_label IN ('cc') AND medical_label IN ('cc') AND education_label IN ('cc') AND science_label IN ('cc'))))', '((\"dclm_fasttext_score\" > 0.002 OR \"cosmo_10k_edu_fasttext_score\" > 0.03)) AND (((tokens_per_doc_num_chars BETWEEN 0.1 AND 0.5) AND (technology_computing_label IN ('technology') OR medical_label IN ('medical') OR education_label IN ('education') OR science_label IN ('science'))) OR ((tokens_per_doc_num_chars BETWEEN 0.22 AND 0.28) AND (technology_computing_label IN ('cc') AND medical_label IN ('cc') AND education_label IN ('cc') AND science_label IN ('cc'))))']\n",
    "        ['((\"dclm_fasttext_score\" > 0.002 OR \"cosmo_10k_edu_fasttext_score\" > 0.03)) AND (((mcalpine_eflaw_textstat < 70) AND (technology_computing_label IN (\\'technology\\') OR medical_label IN (\\'medical\\') OR education_label IN (\\'education\\') OR science_label IN (\\'science\\'))) OR ((mcalpine_eflaw_textstat < 30) AND (technology_computing_label IN (\\'cc\\') AND medical_label IN (\\'cc\\') AND education_label IN (\\'cc\\') AND science_label IN (\\'cc\\'))))',\n",
    "         '((\"dclm_fasttext_score\" > 0.002 OR \"cosmo_10k_edu_fasttext_score\" > 0.03)) AND (((tokens_per_doc_num_chars BETWEEN 0.1 AND 0.5) AND (technology_computing_label IN (\\'technology\\') OR medical_label IN (\\'medical\\') OR education_label IN (\\'education\\') OR science_label IN (\\'science\\'))) OR ((tokens_per_doc_num_chars BETWEEN 0.22 AND 0.28) AND (technology_computing_label IN (\\'cc\\') AND medical_label IN (\\'cc\\') AND education_label IN (\\'cc\\') AND science_label IN (\\'cc\\'))))'],\n",
    "        filter_logical_operator= \"OR\").transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f32b727-2cc4-4ab9-9b88-50f0ccc64de1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
