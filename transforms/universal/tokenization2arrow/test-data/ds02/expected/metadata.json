{
    "pipeline": "pipeline_id",
    "job details": {
        "job category": "preprocessing",
        "job name": "Tokenization2Arrow",
        "job type": "pure python",
        "job id": "job_id",
        "start_time": "2025-02-10 14:21:29",
        "end_time": "2025-02-10 14:21:52",
        "status": "success"
    },
    "code": null,
    "job_input_params": {
        "tokenizer": "hf-internal-testing/llama-tokenizer",
        "tokenizer_args": null,
        "doc_id_column": "document_id",
        "doc_content_column": "contents",
        "text_lang": "en",
        "chunk_size": 0,
        "checkpointing": false,
        "max_files": -1,
        "random_samples": -1,
        "files_to_use": [".parquet"],
        "num_processors": 0
    },
    "execution_stats": {
        "cpus": 33.7,
        "gpus": 0,
        "memory": 14.31,
        "object_store": 0,
        "execution time, min": 0.377
    },
    "job_output_stats": {
        "source_files": 1,
        "source_size": 7189551,
        "result_files": 1,
        "result_size": 18548714,
        "processing_time": 22.432,
        "num_files": 1,
        "num_rows": 1,
        "num_tokenized_rows": 1,
        "num_empty_rows": 0,
        "num_tokens": 4637064,
        "num_chars": 16836009,
        "result_doc_count": 0
    },
    "source": {
        "name": "/Users/santoshborse/development/IBM/data-prep-kit/transforms/universal/tokenization2arrow/test-data/ds02/input",
        "type": "path"
    },
    "target": {
        "name": "/Users/santoshborse/development/IBM/data-prep-kit/transforms/universal/tokenization2arrow/output/ds02",
        "type": "path"
    }
}
